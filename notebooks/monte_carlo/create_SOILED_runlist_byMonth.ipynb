{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d226e52-3320-4e3e-92e0-f34de8f79501",
   "metadata": {},
   "source": [
    "---\n",
    "# Create ordered list of SOILED netcdf output from monte-carlo \n",
    "# Identify missing/incomplete runs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb60d6-620d-408e-8ee6-b7825a1d0d73",
   "metadata": {},
   "source": [
    "The monte carlo runs were completed on Compute Canada's supercomputer, `Graham` and this code is intended to be used on that system.  It requires initialization of a Virtual Environment.  See `/home/rmueller/projects/def-allen/rmueller/graham-jupyter-env.txt`.\n",
    "\n",
    "First initiate a compute node (no heavy-lifting in this example) with: \n",
    "```\n",
    "salloc --time=1:00:00 --ntasks=1 --cpus-per-task=1 --mem-per-cpu=1024M --account=rrg-allen\n",
    "```\n",
    "Activate `VENV` with:\n",
    "```\n",
    "module load python/3.8.2\n",
    "source ~/venvs/jupyter/bin/activate\n",
    "```\n",
    "Deactivate `VENV` with:\n",
    "```\n",
    "deactivate\n",
    "```\n",
    "If the `jupyter` `VENV` is not yet setup, install it with:\n",
    "```\n",
    "module load python/3.8.2\n",
    "python3 -m virtualenv --no-download ~/venvs/jupyter\n",
    "source ~/venvs/jupyter/bin/activate\n",
    "python3 -m pip install --no-index --upgrade pip\n",
    "python3 -m pip install -r /home/rmueller/projects/def-allen/rmueller/graham-jupyter-env.txt\n",
    "```\n",
    "\n",
    "This environment is setup to allow user to initiate a remote window using:\n",
    "```\n",
    "jupyter lab --no-browser --ip $(hostname -f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf84f1b-7660-4fdb-864a-26f3fe2cd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import yaml\n",
    "import xarray\n",
    "import h5netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776315ac-6467-474b-a8f1-098a03592707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SOILED_netcdf_filenames_byMonth(\n",
    "    results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo',\n",
    "    output_dir ='/scratch/rmueller/MIDOSS/Results',\n",
    "    runset_tag=\"*_near-BP_try3*\"):\n",
    "    \"\"\"Get lists of filepaths and filenames for netcdf files of model output, \n",
    "    grouped by oil types. NOTE: jet and gas are run as diesel; other is run \n",
    "    as bunker.  \n",
    "    \n",
    "    :param str results_dir: File path for root directory of run sets. \n",
    "    On Graham, the filepath is `/scratch/dlatorne/MIDOSS/runs/monte-carlo`\n",
    "    \n",
    "    :param str output_dir: File path for storing MOHID_results_locations_{date}.yaml,\n",
    "    which contains file paths for completed runs, sorted by oil type.  \n",
    "    \n",
    "    :return: Dataframe of file paths and names, sorted by oil types, namely: \n",
    "    akns, bunker, dilbit, jet, diesel, gas and other.  Note: jet and gas are \n",
    "    run as diesel; other is run as bunker.  \n",
    "    :rtype: :py:class:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    # get list of runsets\n",
    "    # for newer runs, use: \"*_near-BP_*\"\n",
    "    runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "    # get list of runs within each runset\n",
    "    runs = []\n",
    "    for runset in runsets:\n",
    "        runs.extend(sorted(\n",
    "            glob(os.path.join(runset,'results',runset_tag)))[:])        \n",
    "    # get complete list of netcdf files\n",
    "    netcdf_files = []\n",
    "    files_byMonth = {}\n",
    "    month_names={\n",
    "        1:'Jan',\n",
    "        2:'Feb',\n",
    "        3:'Mar',\n",
    "        4:'Apr',\n",
    "        5:'May',\n",
    "        6:'Jun',\n",
    "        7:'Jul',\n",
    "        8:'Aug',\n",
    "        9:'Sep',\n",
    "        10:'Oct',\n",
    "        11:'Nov',\n",
    "        12:'Dec'\n",
    "    }\n",
    "    for month in month_names:\n",
    "        files_byMonth[month_names[month]]=[]\n",
    "    files_byMonth['all'] = []\n",
    "    for run in runs:\n",
    "        nrun = run.split('/')[-1].split('-')[-1]\n",
    "        try:\n",
    "            dat_file_path=glob(os.path.join(run,f'MassBalance*.sro'))[0]\n",
    "        except:\n",
    "            print(f'No MassBalance*.sro: {run}')\n",
    "            continue\n",
    "        try:\n",
    "            dat_file = open(dat_file_path, 'r')\n",
    "        except:\n",
    "            print(dat_file_path)\n",
    "            continue\n",
    "        for position, line in enumerate(dat_file):\n",
    "            if position==2:\n",
    "                spill_dateTime = line\n",
    "                MM = spill_dateTime.split('.')[1]\n",
    "                files_byMonth[month_names[int(MM)]].extend(glob(os.path.join(run,'Lagrangian*.nc')))\n",
    "                files_byMonth['all'].extend(glob(os.path.join(run,'Lagrangian*.nc')))\n",
    "    # write filenames to .yaml with timestamp in filename\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
    "    out_f = output_dir+f'/MOHID_results_locationsByMonth_try3_{dt_string}.yaml'\n",
    "    try:\n",
    "        with open(out_f, 'w') as output_yaml:\n",
    "            documents = yaml.safe_dump(files_byMonth, output_yaml)\n",
    "    except:\n",
    "        print(\"Save to yaml didn't work\")\n",
    "    return files_byMonth, runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42494711-8c84-4469-9efc-b800845403b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 25.5 s, total: 39.4 s\n",
      "Wall time: 14min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo'\n",
    "output_dir ='/scratch/rmueller/MIDOSS/Results'\n",
    "files_byMonth,runs = get_SOILED_netcdf_filenames_byMonth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3026781-3863-4478-a16e-128907dc0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan: 717 runs\n",
      "Feb: 627 runs\n",
      "Mar: 798 runs\n",
      "Apr: 760 runs\n",
      "May: 847 runs\n",
      "Jun: 870 runs\n",
      "Jul: 928 runs\n",
      "Aug: 876 runs\n",
      "Sep: 886 runs\n",
      "Oct: 885 runs\n",
      "Nov: 838 runs\n",
      "Dec: 801 runs\n",
      "all: 9833 runs\n",
      "TOTAL RUNS: 9833\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "time_per_file = 0.575\n",
    "minutes_to_hours = 1/60\n",
    "for month in [*files_byMonth]:\n",
    "    number_of_files = len(files_byMonth[month])\n",
    "    print(f'{month}: {number_of_files} runs')\n",
    "    if month!='all':\n",
    "        total+=number_of_files\n",
    "print(f'TOTAL RUNS: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbea2a-cb14-4035-9740-de29de7e8d81",
   "metadata": {},
   "source": [
    "### Find missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc0c5cf-da84-46b4-ad0c-376c6c2a76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "runset_tag=\"*_near-BP_try3*\"\n",
    "# get list of runsets\n",
    "runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "finished = pandas.DataFrame({'filenames':files_byMonth['all']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625d2a7a-8343-4ad0-9939-84631fbd352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-200_near-BP_try3_2022-05-20T133826 : 197 of 200\n",
      "41-200_near-BP_try3_2022-05-22T142401 : 199 of 200\n",
      "42-200_near-BP_try3_2022-05-22T142453 : 195 of 200\n",
      "50-200_near-BP_try3_2022-05-23T130812 : 32 of 200\n"
     ]
    }
   ],
   "source": [
    "list_of_incomplete = []\n",
    "n_missing = 0\n",
    "for runset in runsets: \n",
    "    finished_runset = finished[finished['filenames'].str.contains(runset)]\n",
    "    nruns = f'{runset}'.split('-')[2:][0].split('_')[0]\n",
    "    nruns_finished = len(finished_runset)\n",
    "    if int(nruns)!=nruns_finished:\n",
    "        if nruns_finished>0:\n",
    "            print(f'{runset}'.split('/')[-1],f': {nruns_finished} of {nruns}')\n",
    "            list_of_incomplete.append(f'{runset}'.split('/')[-1])\n",
    "            n_missing+=int(nruns)-nruns_finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aeaa966-6cf2-4af8-93b1-27e4ccd30d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_runs={}\n",
    "completed_runs={}\n",
    "for runset in list_of_incomplete: \n",
    "    completed_runs[runset]=[]\n",
    "    finished_runset = finished[finished['filenames'].str.contains(runset)]\n",
    "    for run in finished_runset['filenames']:\n",
    "        completed_runs[runset].append(int(run.split('.')[0].split('-')[-1]))\n",
    "    completed_runs[runset].sort()\n",
    "    for i in range(len(completed_runs[runset]) - 1):\n",
    "        #print(completed_runs[runset][i],completed_runs[runset][i+1])\n",
    "        if (completed_runs[runset][i+1] - completed_runs[runset][i])>1:\n",
    "            run_list = numpy.arange(\n",
    "                completed_runs[runset][i]+1,completed_runs[runset][i+1]\n",
    "            )\n",
    "            if runset in missing_runs:\n",
    "                missing_runs[runset]=numpy.append(missing_runs[runset],run_list)\n",
    "            else:\n",
    "                missing_runs[runset]=run_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7f39025-7f1c-4a92-849e-d4c2d472eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for runset in [*missing_runs]:\n",
    "     missing_runs[runset]=missing_runs[runset].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc91c1e7-67c5-46f4-baf6-587ed4e63117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('/scratch/rmueller/MIDOSS/Results/'+'missing_runs.yaml', 'w') as outfile:\n",
    "    yaml.safe_dump(missing_runs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277af1e5-cf14-4be7-85ac-51ee9c020cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'31-200_near-BP_try3_2022-05-20T133826': [9, 25, 120],\n",
       " '41-200_near-BP_try3_2022-05-22T142401': [116],\n",
       " '42-200_near-BP_try3_2022-05-22T142453': [21, 74, 79, 83, 94],\n",
       " '50-200_near-BP_try3_2022-05-23T130812': [18]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace1bd4-6b6a-4670-b7a5-ec9de8f5f5f5",
   "metadata": {},
   "source": [
    "## plot locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c0e6b-a234-4b32-b74c-07668b897b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b36de7-e289-495a-8930-e6a0d73818e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "mesh2d = xarray.open_dataset('https://salishsea.eos.ubc.ca/erddap/griddap/ubcSSn2DMeshMaskV17-02.html', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdfaf2-23c5-4b07-8db3-5c9ca0f8cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SalishSea_1d_20151227_20151227_ptrc_T.nc'\n",
    "grid_g = nc.Dataset(filename)\n",
    "conc = grid_g.variables[field]\n",
    "\n",
    "#Prepare surface values\n",
    "conc_ma = np.ma.masked_values(conc[0, 0, :, :], 0)\n",
    "# use tmask (meshmask file) instead\n",
    "vmin = np.min(conc_ma)\n",
    "vmax = np.max(conc_ma)\n",
    "\n",
    "#Prepare thalweg values\n",
    "npconc = conc[:]\n",
    "conc_t = npconc[0, :, thalweg[0], thalweg[1]]\n",
    "conc_t_ma = np.ma.masked_values(conc_t, 0)\n",
    "vmin_t = np.min(conc_t_ma)\n",
    "vmax_t = np.max(conc_t_ma)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "land_colour = 'burlywood'\n",
    "for ax in (ax2, ax1):\n",
    "    ax.set_axis_bgcolor(land_colour)\n",
    "ax1.set_position((0.125, 0.125, 0.5, 0.775))\n",
    "#axcb.set_position((0.73, 0.125, 0.02, 0.775))\n",
    "ax2.set_position((0.8, 0.125, 0.2, 0.775))\n",
    "\n",
    "set_aspect(ax2)\n",
    "cmap = plt.get_cmap('Greens')\n",
    "cmap.set_bad('burlywood')\n",
    "\n",
    "#Surface plot\n",
    "mesh = ax2.pcolormesh(conc_ma, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "cbar = fig.colorbar(mesh, ax=ax2)\n",
    "#plt.axis(0, conc_ma.shape[1], 0, conc_ma.shape[0])\n",
    "ax2.set_title('Surface {label}'.format(label=conc.long_name.title()), fontsize=16)\n",
    "ax2.set_xlabel('x Index')\n",
    "ax2.set_ylabel('y Index')\n",
    "cbar.set_label('{label} [{units}]'.format(label=conc.long_name.title(), units=conc.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538f172-8318-448d-88e3-f81d00514e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
