{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d226e52-3320-4e3e-92e0-f34de8f79501",
   "metadata": {},
   "source": [
    "---\n",
    "# Create ordered list of SOILED .sro output files from monte-carlo \n",
    "# Identify missing/incomplete runs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb60d6-620d-408e-8ee6-b7825a1d0d73",
   "metadata": {},
   "source": [
    "The monte carlo runs were completed on Compute Canada's supercomputer, `Graham` and this code is intended to be used on that system.  It requires initialization of a Virtual Environment.  See `/home/rmueller/projects/def-allen/rmueller/graham-jupyter-env.txt`.\n",
    "\n",
    "First initiate a compute node (no heavy-lifting in this example) with: \n",
    "```\n",
    "salloc --time=1:00:00 --ntasks=1 --cpus-per-task=1 --mem-per-cpu=1024M --account=rrg-allen\n",
    "```\n",
    "Activate `VENV` with:\n",
    "```\n",
    "module load python/3.8.2\n",
    "source ~/venvs/jupyter/bin/activate\n",
    "```\n",
    "Deactivate `VENV` with:\n",
    "```\n",
    "deactivate\n",
    "```\n",
    "If the `jupyter` `VENV` is not yet setup, install it with:\n",
    "```\n",
    "module load python/3.8.2\n",
    "python3 -m virtualenv --no-download ~/venvs/jupyter\n",
    "source ~/venvs/jupyter/bin/activate\n",
    "python3 -m pip install --no-index --upgrade pip\n",
    "python3 -m pip install -r /home/rmueller/projects/def-allen/rmueller/graham-jupyter-env.txt\n",
    "```\n",
    "\n",
    "This environment is setup to allow user to initiate a remote window using:\n",
    "```\n",
    "jupyter lab --no-browser --ip $(hostname -f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf84f1b-7660-4fdb-864a-26f3fe2cd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from os.path import exists\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import yaml\n",
    "import xarray\n",
    "import h5netcdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c31dc6-81ad-4642-be85-28c4d81d7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_types = [\n",
    "    'akns', \n",
    "    'bunker', \n",
    "    'dilbit', \n",
    "    'jet', \n",
    "    'diesel', \n",
    "    'gas', \n",
    "    'other'\n",
    "]\n",
    "output_dir ='/scratch/rmueller/MIDOSS/Results/try3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae74b319-c09b-413c-9e68-5c882c58d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.11 s, sys: 8 s, total: 12.1 s\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo'\n",
    "# specify directory search tags\n",
    "runset_tag = \"*_near-BP_try3*\"\n",
    "\n",
    "# get list of runsets\n",
    "runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "# get list of runs within each runset\n",
    "runs = []\n",
    "sro_files = []\n",
    "netcdf_files = []\n",
    "missing_netcdf = []\n",
    "for runset in runsets:\n",
    "    runs.extend(sorted(\n",
    "        glob(os.path.join(runset,\"results\",runset_tag)))[:])\n",
    "for run in runs:\n",
    "    # There are 9833 netcdf and 9841 sro files.  I only choose .sro files\n",
    "    # where netcdf exist\n",
    "    try:\n",
    "        exists(glob(os.path.join(run,'*.nc'))[0])\n",
    "    except:\n",
    "        missing_netcdf.append(os.path.join(run,'*.nc'))\n",
    "    else:    \n",
    "        sro_files.append(sorted(\n",
    "            glob(os.path.join(run,'*.sro')))[0])\n",
    "        netcdf_files.append(sorted(\n",
    "            glob(os.path.join(run,'*.nc')))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63fdefc8-1eb1-4505-89c4-0f644429659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort filenames by oil type.  \n",
    "file_boolean = {}\n",
    "files = {}\n",
    "files['all'] = []\n",
    "for oil in oil_types:\n",
    "    # Use lagrangian filename to ID and allocate .sro oil type\n",
    "    file_boolean[oil] = [oil in file for file in netcdf_files]\n",
    "    files[oil]=[file for i,file in enumerate(sro_files) \\\n",
    "        if file_boolean[oil][i]]\n",
    "    files['all'].extend(files[oil])\n",
    "files['all'].sort()\n",
    "# write filenames to .yaml with timestamp in filename\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
    "out_f = output_dir+f'/MOHID_massbalance_try3_{dt_string}.yaml'\n",
    "with open(out_f, 'w') as output_yaml:\n",
    "    documents = yaml.safe_dump(files, output_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbafbe81-c45c-44e9-ae84-2fd3206db20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9833"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sro_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6448fe5d-8f9d-4b44-8716-afdc473fff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SOILED_sro_filenames_byMonth(\n",
    "    results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo',\n",
    "    output_dir ='/scratch/rmueller/MIDOSS/Results/try3',\n",
    "    runset_tag=\"*_near-BP_try3*\"):\n",
    "    \"\"\"Get lists of filepaths and filenames for netcdf files of model output, \n",
    "    grouped by oil types. NOTE: jet and gas are run as diesel; other is run \n",
    "    as bunker.  \n",
    "    \n",
    "    :param str results_dir: File path for root directory of run sets. \n",
    "    On Graham, the filepath is `/scratch/dlatorne/MIDOSS/runs/monte-carlo`\n",
    "    \n",
    "    :param str output_dir: File path for storing MOHID_results_locations_{date}.yaml,\n",
    "    which contains file paths for completed runs, sorted by oil type.  \n",
    "    \n",
    "    :return: Dataframe of file paths and names, sorted by oil types, namely: \n",
    "    akns, bunker, dilbit, jet, diesel, gas and other.  Note: jet and gas are \n",
    "    run as diesel; other is run as bunker.  \n",
    "    :rtype: :py:class:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    # get list of runsets\n",
    "    # for newer runs, use: \"*_near-BP_*\"\n",
    "    runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "    # get list of runs within each runset\n",
    "    runs = []\n",
    "    for runset in runsets:\n",
    "        runs.extend(sorted(\n",
    "            glob(os.path.join(runset,'results',runset_tag)))[:])        \n",
    "    # get complete list of netcdf files\n",
    "    sro_files = []\n",
    "    files_byMonth = {}\n",
    "    month_names={\n",
    "        1:'Jan',\n",
    "        2:'Feb',\n",
    "        3:'Mar',\n",
    "        4:'Apr',\n",
    "        5:'May',\n",
    "        6:'Jun',\n",
    "        7:'Jul',\n",
    "        8:'Aug',\n",
    "        9:'Sep',\n",
    "        10:'Oct',\n",
    "        11:'Nov',\n",
    "        12:'Dec'\n",
    "    }\n",
    "    for month in month_names:\n",
    "        files_byMonth[month_names[month]]=[]\n",
    "    files_byMonth['all'] = []\n",
    "    for run in runs:\n",
    "        nrun = run.split('/')[-1].split('-')[-1]\n",
    "        try:\n",
    "            dat_file_path=glob(os.path.join(run,f'MassBalance*.sro'))[0]\n",
    "        except:\n",
    "            print(f'No MassBalance*.sro: {run}')\n",
    "            continue\n",
    "        try:\n",
    "            dat_file = open(dat_file_path, 'r')\n",
    "        except:\n",
    "            print(dat_file_path)\n",
    "            continue\n",
    "        for position, line in enumerate(dat_file):\n",
    "            if position==2:\n",
    "                spill_dateTime = line\n",
    "                MM = spill_dateTime.split('.')[1]\n",
    "                files_byMonth[month_names[int(MM)]].extend(glob(os.path.join(run,'MassBalance*.sro')))\n",
    "                files_byMonth['all'].extend(glob(os.path.join(run,'MassBalance*.sro')))\n",
    "    # write filenames to .yaml with timestamp in filename\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
    "    out_f = output_dir+f'/MOHID_sro_ByMonth_try3_{dt_string}.yaml'\n",
    "    try:\n",
    "        with open(out_f, 'w') as output_yaml:\n",
    "            documents = yaml.safe_dump(files_byMonth, output_yaml)\n",
    "    except:\n",
    "        print(\"Save to yaml didn't work\")\n",
    "    return files_byMonth, runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ca358b-98de-488d-9d12-f407fe0e708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_byMonth, runs=get_SOILED_sro_filenames_byMonth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fceef0-d91f-4aea-a36d-9976e36b979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_scratch(results_dir, runset_tag_upper, runset_tag_lower):\n",
    "    \"\"\"Refresh MIDOSS output files on scratch to prevent purge.  \n",
    "    \n",
    "    :param str results_dir: File path for root directory of run sets. \n",
    "    On Graham, the filepath is `/scratch/dlatorne/MIDOSS/runs/monte-carlo`\n",
    "    \n",
    "    :param str runset_tag_upper: directory search tag.  The first set of runs uses\n",
    "       \"near-BP_*\".  The second set of runs uses \"*_near-BP_spill-hr_*\".\n",
    "    \n",
    "    :param str runset_tag_lower: sub-directory search tag.  The first set of runs uses\n",
    "       \"near-BP_*\".  The second set of runs uses \"*_near-BP_spill-hr-*\".  \n",
    "    \n",
    "    :return: lists of filenames that have been refreshed  \n",
    "    \"\"\"\n",
    "    # get list of runsets\n",
    "    runsets = sorted(glob(os.path.join(results_dir,runset_tag_upper)))\n",
    "    # get list of runs within each runset\n",
    "    runs = []\n",
    "    for runset in runsets:\n",
    "        runs.extend(sorted(\n",
    "            glob(os.path.join(runset,\"results\",runset_tag_lower)))[:])        \n",
    "    # collate lists of files and open/close them to refresh\n",
    "    sro_files = []\n",
    "    netcdf_files = []\n",
    "    model_files = []\n",
    "    lagrangian_files = [] \n",
    "    no_files = {}\n",
    "    no_files['sro']=[]\n",
    "    no_files['nc']=[]\n",
    "    no_files['model']=[]\n",
    "    no_files['lagrangian']=[]\n",
    "    for run in runs:\n",
    "        # create complete list of \"refreshed\" files\n",
    "        sro_files.append(glob(os.path.join(run,'*.sro')))\n",
    "        netcdf_files.append(glob(os.path.join(run,'*.nc')))\n",
    "        model_files.append(glob(os.path.join(run,'Model*.dat')))\n",
    "        lagrangian_files.append(glob(os.path.join(run,'Lagrangian*.dat')))\n",
    "        # open/close files to refresh usage on scratch\n",
    "        try:\n",
    "            sro = open(glob(os.path.join(run,'*.sro'))[0])\n",
    "            sro.close()\n",
    "        except:\n",
    "            no_files['sro'].append(run)\n",
    "            print(run,'*.sro')\n",
    "        # netcdf output\n",
    "        try:\n",
    "            nc = xarray.open_dataset(glob(os.path.join(run,'*.nc'))[0])\n",
    "            nc.close()\n",
    "        except:\n",
    "            no_files['nc'].append(run)\n",
    "            print(run,'*.nc')\n",
    "        # Model.dat files\n",
    "        try:\n",
    "            model = open(glob(os.path.join(run,'Model*.dat'))[0])\n",
    "            model.close()\n",
    "        except:\n",
    "            no_files['model'].append(run)\n",
    "            print(run,'Model*.dat')\n",
    "        # Lagrangian files \n",
    "        try: \n",
    "            lagrangian = open(glob(os.path.join(run,'Lagrangian*.dat'))[0])\n",
    "            lagrangian.close()\n",
    "        except:\n",
    "            no_files['lagrangian'].append(run)\n",
    "            print(run,'Lagrangian*.dat') \n",
    "    return sro_files, netcdf_files, model_files, lagrangian_files, no_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafbaef-5a76-41b4-907a-a59701c22f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo'\n",
    "# specify directory search tags\n",
    "# for newer runs, use: \"*_near-BP_*\"\n",
    "runset_tag_upper = \"*_near-BP_spill-hr*\"\n",
    "runset_tag_lower = \"*_near-BP_spill-hr*\"\n",
    "[sro_files, netcdf_files, model_files, lagrangian_files, no_files]=refresh_scratch(\n",
    "    results_dir, runset_tag_upper, runset_tag_lower\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5923ab-acda-48c9-9d18-996a5b379e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fea994-d0fd-451e-8a7d-fdb1added655",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir ='/scratch/rmueller/MIDOSS/Results/scratch_refresh/'\n",
    "output_sro = open(output_dir + \"sro_files.txt\", \"w\")\n",
    "for path in sro_files:\n",
    "    output_sro.write(path + \"\\n\")\n",
    "output_sro.close()\n",
    "\n",
    "output_nc = open(output_dir + \"nc_files.txt\", \"w\")\n",
    "for path in netcdf_files:\n",
    "    output_nc.write(path + \"\\n\")\n",
    "output_nc.close()\n",
    "\n",
    "model_sro = open(output_dir + \"model_files.txt\", \"w\")\n",
    "for path in model_files:\n",
    "    model_sro.write(path + \"\\n\")\n",
    "model_sro.close()\n",
    "\n",
    "lagrangian_sro = open(output_dir + \"lagrangian_files.txt\", \"w\")\n",
    "for path in lagrangian_files:\n",
    "    lagrangian_sro.write(path + \"\\n\")\n",
    "lagrangian_sro.close()\n",
    "\n",
    "with open(output_dir + \"no_files\", 'w') as outfile:\n",
    "    yaml.safe_dump(no_files, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb58bf3-20eb-4415-a11c-e971b7e4a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir + \"no_files\", 'r') as outfile:\n",
    "    nogo = yaml.safe_load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289ca36-def5-4465-8080-055b13b3745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refresh Based on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
