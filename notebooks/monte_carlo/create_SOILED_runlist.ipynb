{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d226e52-3320-4e3e-92e0-f34de8f79501",
   "metadata": {},
   "source": [
    "---\n",
    "# Create ordered list of SOILED netcdf output from monte-carlo \n",
    "# Identify missing/incomplete runs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb60d6-620d-408e-8ee6-b7825a1d0d73",
   "metadata": {},
   "source": [
    "The monte carlo runs were completed on Compute Canada's supercomputer, `Graham` and this code is intended to be used on that system.  It requires initialization of a Virtual Environment.  See `/home/rmueller/projects/def-allen/rmueller/graham-jupyter-env.txt`.\n",
    "\n",
    "First initiate a compute node (no heavy-lifting in this example) with: \n",
    "```\n",
    "salloc --time=1:00:00 --ntasks=1 --cpus-per-task=1 --mem-per-cpu=1024M --account=rrg-allen\n",
    "```\n",
    "Activate `VENV` with:\n",
    "```\n",
    "module load python/3.8.2\n",
    "source ~/venvs/jupyter/bin/activate\n",
    "```\n",
    "Deactivate `VENV` with:\n",
    "```\n",
    "deactivate\n",
    "```\n",
    "If the `jupyter` `VENV` is not yet setup, install it with:\n",
    "```\n",
    "module load python/3.8.2\n",
    "python3 -m virtualenv --no-download ~/venvs/jupyter\n",
    "source ~/venvs/jupyter/bin/activate\n",
    "python3 -m pip install --no-index --upgrade pip\n",
    "python3 -m pip install -r /home/rmueller/projects/def-allen/rmueller/graham-jupyter-env.txt\n",
    "```\n",
    "\n",
    "This environment is setup to allow user to initiate a remote window using:\n",
    "```\n",
    "jupyter lab --no-browser --ip $(hostname -f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf84f1b-7660-4fdb-864a-26f3fe2cd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import numpy\n",
    "import yaml\n",
    "import xarray\n",
    "import h5netcdf\n",
    "sys.path.insert(1, '../../scripts/monte_carlo')\n",
    "from aggregate_SOILED_tools import get_SOILED_netcdf_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f727e5e3-0ad3-441d-a563-f51c840e9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_purge_file='/home/scratch_to_delete/dlatorne'\n",
    "output_dir ='/scratch/rmueller/MIDOSS/Results/'\n",
    "# with open(scratch_purge_file, \"r\") as fd:\n",
    "#     files_to_refresh = fd.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776315ac-6467-474b-a8f1-098a03592707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SOILED_netcdf_filenames(\n",
    "    results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo', \n",
    "    output_dir='/scratch/rmueller/MIDOSS/Results', \n",
    "    runset_tag = \"*_near-BP_try3*\"):\n",
    "    \"\"\"Get lists of filepaths and filenames for netcdf files of model output, \n",
    "    grouped by oil types. NOTE: jet and gas are run as diesel; other is run \n",
    "    as bunker.  \n",
    "    \n",
    "    :param str results_dir: File path for root directory of run sets. \n",
    "    On Graham, the filepath is `/scratch/dlatorne/MIDOSS/runs/monte-carlo`\n",
    "    \n",
    "    :param str output_dir: File path for storing MOHID_results_locations_{date}.yaml,\n",
    "    which contains file paths for completed runs, sorted by oil type.  \n",
    "    \n",
    "    :return: Dataframe of file paths and names, sorted by oil types, namely: \n",
    "    akns, bunker, dilbit, jet, diesel, gas and other.  Note: jet and gas are \n",
    "    run as diesel; other is run as bunker.  \n",
    "    :rtype: :py:class:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    oil_types = [\n",
    "        'akns', \n",
    "        'bunker', \n",
    "        'dilbit', \n",
    "        'jet', \n",
    "        'diesel', \n",
    "        'gas', \n",
    "        'other'\n",
    "    ]\n",
    "    # get list of runsets\n",
    "    # for newer runs, use: \"*_near-BP_*\"\n",
    "    runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "    # get list of runs within each runset\n",
    "    runs = []\n",
    "    for runset in runsets:\n",
    "        runs.extend(sorted(\n",
    "            glob(os.path.join(runset,'results',runset_tag)))[:])        \n",
    "    # get complete list of netcdf files\n",
    "    netcdf_files = []\n",
    "    for run in runs:\n",
    "        netcdf_files.extend(sorted(\n",
    "            glob(os.path.join(run,'Lagrangian*.nc')))[:])\n",
    "    # sort filenames by oil type.  \n",
    "    file_boolean = {}\n",
    "    files = {}\n",
    "    files['all'] = []\n",
    "    for oil in oil_types:\n",
    "        file_boolean[oil] = [oil in file for file in netcdf_files]\n",
    "        files[oil]=[file for i,file in enumerate(netcdf_files) \\\n",
    "            if file_boolean[oil][i]]\n",
    "        files['all'].extend(files[oil])\n",
    "    files['all'].sort()\n",
    "    # write filenames to .yaml with timestamp in filename\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y_%H:%M:%S\")\n",
    "    out_f = output_dir+f'/MOHID_results_locations_try3_{dt_string}.yaml'\n",
    "    with open(out_f, 'w') as output_yaml:\n",
    "        documents = yaml.safe_dump(files, output_yaml)\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42494711-8c84-4469-9efc-b800845403b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir='/scratch/dlatorne/MIDOSS/runs/monte-carlo'\n",
    "output_dir ='/scratch/rmueller/MIDOSS/Results'\n",
    "runset_tag=\"*_near-BP_try3*\"\n",
    "files = get_SOILED_netcdf_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3026781-3863-4478-a16e-128907dc0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akns: 64 runs, approx 0.61 hours to complete\n",
      "bunker: 3347 runs, approx 32.08 hours to complete\n",
      "dilbit: 1 runs, approx 0.01 hours to complete\n",
      "jet: 26 runs, approx 0.25 hours to complete\n",
      "diesel: 6250 runs, approx 59.90 hours to complete\n",
      "gas: 76 runs, approx 0.73 hours to complete\n",
      "other: 69 runs, approx 0.66 hours to complete\n",
      "TOTAL RUNS: 9833\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "time_per_file = 0.575\n",
    "minutes_to_hours = 1/60\n",
    "oil_types = [\n",
    "        'akns', \n",
    "        'bunker', \n",
    "        'dilbit', \n",
    "        'jet', \n",
    "        'diesel', \n",
    "        'gas', \n",
    "        'other'\n",
    "    ]\n",
    "for oil in oil_types:\n",
    "    number_of_files = len(files[oil])\n",
    "    time_to_complete = time_per_file * number_of_files * minutes_to_hours\n",
    "    print(f'{oil}: {number_of_files} runs, approx {time_to_complete:.2f} hours to complete')\n",
    "    total+=len(files[oil])\n",
    "print(f'TOTAL RUNS: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cbea2a-cb14-4035-9740-de29de7e8d81",
   "metadata": {},
   "source": [
    "### Find missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc0c5cf-da84-46b4-ad0c-376c6c2a76e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of runsets\n",
    "runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "finished = pandas.DataFrame({'filenames':files['all']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7469d30e-3a97-49d6-89d6-af0a7e87bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of runsets\n",
    "runsets = sorted(glob(os.path.join(results_dir,runset_tag)))\n",
    "finished = pandas.DataFrame({'filenames':files['all']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5e30c2-d901-447a-82fa-3014f98553c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'runset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20168/3373852792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'runset' is not defined"
     ]
    }
   ],
   "source": [
    "runset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d2a7a-8343-4ad0-9939-84631fbd352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_incomplete = []\n",
    "n_missing = 0\n",
    "for runset in runsets: \n",
    "    finished_runset = finished[finished['filenames'].str.contains(runset)]\n",
    "    nruns = f'{runset}'.split('-')[2:][0].split('_')[0]\n",
    "    nruns_finished = len(finished_runset)\n",
    "    if int(nruns)!=nruns_finished:\n",
    "        if nruns_finished>0:\n",
    "            print(f'{runset}'.split('/')[-1],f': {nruns_finished} of {nruns}')\n",
    "            list_of_incomplete.append(f'{runset}'.split('/')[-1])\n",
    "            n_missing+=int(nruns)-nruns_finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeaa966-6cf2-4af8-93b1-27e4ccd30d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_runs={}\n",
    "completed_runs={}\n",
    "for runset in list_of_incomplete: \n",
    "    completed_runs[runset]=[]\n",
    "    finished_runset = finished[finished['filenames'].str.contains(runset)]\n",
    "    for run in finished_runset['filenames']:\n",
    "        completed_runs[runset].append(int(run.split('.')[0].split('-')[-1]))\n",
    "    completed_runs[runset].sort()\n",
    "    for i in range(len(completed_runs[runset]) - 1):\n",
    "        #print(completed_runs[runset][i],completed_runs[runset][i+1])\n",
    "        if (completed_runs[runset][i+1] - completed_runs[runset][i])>1:\n",
    "            run_list = numpy.arange(\n",
    "                completed_runs[runset][i]+1,completed_runs[runset][i+1]\n",
    "            )\n",
    "            if runset in missing_runs:\n",
    "                missing_runs[runset]=numpy.append(missing_runs[runset],run_list)\n",
    "            else:\n",
    "                missing_runs[runset]=run_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f39025-7f1c-4a92-849e-d4c2d472eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for runset in [*missing_runs]:\n",
    "     missing_runs[runset]=missing_runs[runset].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91c1e7-67c5-46f4-baf6-587ed4e63117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('/scratch/rmueller/MIDOSS/Results/'+'missing_runs.yaml', 'w') as outfile:\n",
    "    yaml.safe_dump(missing_runs, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277af1e5-cf14-4be7-85ac-51ee9c020cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace1bd4-6b6a-4670-b7a5-ec9de8f5f5f5",
   "metadata": {},
   "source": [
    "## plot locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b36de7-e289-495a-8930-e6a0d73818e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "mesh2d = xarray.open_dataset('https://salishsea.eos.ubc.ca/erddap/griddap/ubcSSn2DMeshMaskV17-02.html', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdfaf2-23c5-4b07-8db3-5c9ca0f8cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SalishSea_1d_20151227_20151227_ptrc_T.nc'\n",
    "grid_g = nc.Dataset(filename)\n",
    "conc = grid_g.variables[field]\n",
    "    \n",
    "    #Prepare surface values\n",
    "    conc_ma = np.ma.masked_values(conc[0, 0, :, :], 0)\n",
    "    # use tmask (meshmask file) instead\n",
    "    vmin = np.min(conc_ma)\n",
    "    vmax = np.max(conc_ma)\n",
    "   \n",
    "    #Prepare thalweg values\n",
    "    npconc = conc[:]\n",
    "    conc_t = npconc[0, :, thalweg[0], thalweg[1]]\n",
    "    conc_t_ma = np.ma.masked_values(conc_t, 0)\n",
    "    vmin_t = np.min(conc_t_ma)\n",
    "    vmax_t = np.max(conc_t_ma)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    land_colour = 'burlywood'\n",
    "    for ax in (ax2, ax1):\n",
    "        ax.set_axis_bgcolor(land_colour)\n",
    "    ax1.set_position((0.125, 0.125, 0.5, 0.775))\n",
    "    #axcb.set_position((0.73, 0.125, 0.02, 0.775))\n",
    "    ax2.set_position((0.8, 0.125, 0.2, 0.775))\n",
    "    \n",
    "    set_aspect(ax2)\n",
    "    cmap = plt.get_cmap('Greens')\n",
    "    cmap.set_bad('burlywood')\n",
    "    \n",
    "    #Surface plot\n",
    "    mesh = ax2.pcolormesh(conc_ma, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    cbar = fig.colorbar(mesh, ax=ax2)\n",
    "    #plt.axis(0, conc_ma.shape[1], 0, conc_ma.shape[0])\n",
    "    ax2.set_title('Surface {label}'.format(label=conc.long_name.title()), fontsize=16)\n",
    "    ax2.set_xlabel('x Index')\n",
    "    ax2.set_ylabel('y Index')\n",
    "    cbar.set_label('{label} [{units}]'.format(label=conc.long_name.title(), units=conc.units))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
